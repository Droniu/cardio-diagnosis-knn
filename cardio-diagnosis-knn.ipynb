{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing & feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Feature no. 13, Score: 101.985062\n",
      "2. Feature no. 12, Score: 70.098351\n",
      "3. Feature no. 9, Score: 57.169632\n",
      "4. Feature no. 8, Score: 56.908981\n",
      "5. Feature no. 3, Score: 56.554451\n",
      "6. Feature no. 10, Score: 54.564568\n",
      "7. Feature no. 11, Score: 34.477673\n",
      "8. Feature no. 2, Score: 26.065310\n",
      "9. Feature no. 1, Score: 12.651622\n",
      "10. Feature no. 7, Score: 9.190846\n",
      "11. Feature no. 4, Score: 6.630479\n",
      "12. Feature no. 5, Score: 5.024383\n",
      "13. Feature no. 6, Score: 0.071390\n"
     ]
    }
   ],
   "source": [
    "#%%writefile \"select-filter.py\"\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# loading data to tables\n",
    "file = open(\"heart.dat\")\n",
    "all = np.loadtxt(file, delimiter=\" \")\n",
    "X = np.zeros((len(all), len(all[0]) - 1), dtype=np.uint8)\n",
    "y = np.zeros((len(all)), dtype=np.uint8)\n",
    "for i in range(len(all)):\n",
    "    for j in range(len(all[0]) - 1):\n",
    "        X[i][j] = all[i][j]\n",
    "    y[i] = all[i][len(all[0]) - 1]\n",
    "    \n",
    "features_quantity = len(X[0]-1)\n",
    "\n",
    "# feature selection\n",
    "featureSelection = SelectKBest(f_classif)\n",
    "featureSelection.fit(X, y)\n",
    "\n",
    "# sorting by relevance\n",
    "toSort = np.zeros(\n",
    "    (len(featureSelection.scores_)), dtype=([(\"key\", \"<i4\"), (\"val\", \"<f8\")])\n",
    ")\n",
    "for i in range(len(featureSelection.scores_)):\n",
    "    toSort[i][\"key\"] = i + 1\n",
    "    toSort[i][\"val\"] = featureSelection.scores_[i]\n",
    "toSort = np.sort(toSort, order=\"val\")[::-1]\n",
    "\n",
    "feature_order = [] \n",
    "for i in range(features_quantity):\n",
    "    print(\"%d. Feature no. %d, Score: %f\" % (i+1, toSort[i][0], toSort[i][1]))\n",
    "    feature_order.append(toSort[i][0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the dataset\n",
    "For convenience reasons, the dataset columns can be sorted by relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   3   2 ...   0   0  66]\n",
      " [  7   0   2 ...   0   0  52]\n",
      " [  7   0   0 ...   0   0   5]\n",
      " ...\n",
      " [  3   0   2 ...   0   0  38]\n",
      " [  6   0   0 ...   0   0 192]\n",
      " [  3   3   2 ...   1   0  30]]\n"
     ]
    }
   ],
   "source": [
    "def complement(arr):\n",
    "    new_arr = []\n",
    "    for x in range(len(arr)):\n",
    "        new_arr.append(abs(arr[x]-len(arr)))\n",
    "    return np.flip(new_arr)\n",
    "\n",
    "permutation = complement(feature_order)\n",
    "\n",
    "idx = np.empty_like(permutation)\n",
    "idx[permutation] = np.arange(len(permutation))\n",
    "X = X[:, idx]\n",
    "print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first column is the most relevant feature, the second is the second most important and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving data into test set and training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-fold cross validation\n",
    "\n",
    "For validation, 2-fold cross validation repated 5 times is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=2, n_repeats=5, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Alghoritm\n",
    "\n",
    "Chosen k-values are 5, 7, 9 (odd values, because amount of classes is even).\n",
    "Chosen metrics are:\n",
    "- Euclidean distance\n",
    "- Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy(k=5, manhattan metric, top 1 features): 0.691 (0.127)\n",
      "Accuracy(k=7, manhattan metric, top 1 features): 0.699 (0.116)\n",
      "Accuracy(k=9, manhattan metric, top 1 features): 0.666 (0.187)\n",
      "Accuracy(k=5, euclidean metric, top 1 features): 0.691 (0.127)\n",
      "Accuracy(k=7, euclidean metric, top 1 features): 0.699 (0.116)\n",
      "Accuracy(k=9, euclidean metric, top 1 features): 0.666 (0.187)\n",
      "Mean accuracy for top 1 features: 0.685432\n",
      "\n",
      "\n",
      "Accuracy(k=5, manhattan metric, top 2 features): 0.754 (0.019)\n",
      "Accuracy(k=7, manhattan metric, top 2 features): 0.759 (0.029)\n",
      "Accuracy(k=9, manhattan metric, top 2 features): 0.753 (0.027)\n",
      "Accuracy(k=5, euclidean metric, top 2 features): 0.754 (0.019)\n",
      "Accuracy(k=7, euclidean metric, top 2 features): 0.759 (0.029)\n",
      "Accuracy(k=9, euclidean metric, top 2 features): 0.753 (0.027)\n",
      "Mean accuracy for top 2 features: 0.755309\n",
      "\n",
      "\n",
      "Accuracy(k=5, manhattan metric, top 3 features): 0.770 (0.039)\n",
      "Accuracy(k=7, manhattan metric, top 3 features): 0.776 (0.026)\n",
      "Accuracy(k=9, manhattan metric, top 3 features): 0.779 (0.024)\n",
      "Accuracy(k=5, euclidean metric, top 3 features): 0.770 (0.039)\n",
      "Accuracy(k=7, euclidean metric, top 3 features): 0.776 (0.026)\n",
      "Accuracy(k=9, euclidean metric, top 3 features): 0.781 (0.022)\n",
      "Mean accuracy for top 3 features: 0.775062\n",
      "\n",
      "\n",
      "Accuracy(k=5, manhattan metric, top 4 features): 0.736 (0.038)\n",
      "Accuracy(k=7, manhattan metric, top 4 features): 0.738 (0.042)\n",
      "Accuracy(k=9, manhattan metric, top 4 features): 0.739 (0.040)\n",
      "Accuracy(k=5, euclidean metric, top 4 features): 0.714 (0.038)\n",
      "Accuracy(k=7, euclidean metric, top 4 features): 0.710 (0.050)\n",
      "Accuracy(k=9, euclidean metric, top 4 features): 0.699 (0.046)\n",
      "Mean accuracy for top 4 features: 0.722469\n",
      "\n",
      "\n",
      "Accuracy(k=5, manhattan metric, top 5 features): 0.736 (0.044)\n",
      "Accuracy(k=7, manhattan metric, top 5 features): 0.736 (0.048)\n",
      "Accuracy(k=9, manhattan metric, top 5 features): 0.731 (0.040)\n",
      "Accuracy(k=5, euclidean metric, top 5 features): 0.712 (0.044)\n",
      "Accuracy(k=7, euclidean metric, top 5 features): 0.707 (0.052)\n",
      "Accuracy(k=9, euclidean metric, top 5 features): 0.702 (0.044)\n",
      "Mean accuracy for top 5 features: 0.720741\n",
      "\n",
      "\n",
      "Accuracy(k=5, manhattan metric, top 6 features): 0.743 (0.046)\n",
      "Accuracy(k=7, manhattan metric, top 6 features): 0.741 (0.040)\n",
      "Accuracy(k=9, manhattan metric, top 6 features): 0.727 (0.036)\n",
      "Accuracy(k=5, euclidean metric, top 6 features): 0.721 (0.040)\n",
      "Accuracy(k=7, euclidean metric, top 6 features): 0.713 (0.047)\n",
      "Accuracy(k=9, euclidean metric, top 6 features): 0.698 (0.047)\n",
      "Mean accuracy for top 6 features: 0.723827\n",
      "\n",
      "Maximum accuracy: 0.7807407407407407\n",
      "Minimum accuracy: 0.665925925925926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "metric_list = ['manhattan', 'euclidean']\n",
    "max_features = 6\n",
    "\n",
    "highest_acc = 0\n",
    "lowest_acc = 1\n",
    "\n",
    "# print(X_train[:,:2])\n",
    "for top in range(max_features):\n",
    "    print(\"\\n\")\n",
    "    features_train = X[:,:(top+1)]\n",
    "    acc_list = []\n",
    "    for p in metric_list:\n",
    "        for k in range(5, 10, 2):\n",
    "            model = KNeighborsClassifier(n_neighbors=k, metric=p)\n",
    "            scores = cross_val_score(model, features_train, y, scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "            result = mean(scores)\n",
    "            print('Accuracy(k=%d, %s metric, top %d features): %.3f (%.3f)' % (k, p, top+1, result, std(scores)))\n",
    "            acc_list.append(result)\n",
    "            \n",
    "            if result > highest_acc:\n",
    "                highest_acc = result\n",
    "            if result < lowest_acc:\n",
    "                lowest_acc = result\n",
    "    print('Mean accuracy for top %d features: %f' % (top+1, mean(acc_list)))\n",
    "\n",
    "print(\"\\nMaximum accuracy:\", highest_acc)\n",
    "print(\"Minimum accuracy:\", lowest_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis\n",
    "\n",
    "TBD"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7cc3bc10f040823b08e156202303ecc62b74ddcd15b43be2d0df9acb2e0145d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
